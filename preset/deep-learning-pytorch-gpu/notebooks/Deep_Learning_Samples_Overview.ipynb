{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samples to Get Started with AI Tools Selector Deep Learning Preset Container\n",
    "This Container features samples to get started with understanding how ai tools selector presets delivers optimized and scalable solutions for Deep Learning using Jupyterlab.\n",
    "\n",
    "Below are a list of samples included that take advantage of Intel Optimizations for a given AI Tool:\n",
    "1. [ResNet50 Inference with Intel® Extension for PyTorch](./ipex/ResNet50_Inference.ipynb) : This code sample will guide users how to run a PyTorch inference workload on both GPU and CPU by using oneAPI AI Analytics Toolkit and also analyze the GPU and CPU usage via oneDNN verbose logs.\n",
    "2. [Quantization with Intel® Extension for PyTorch](./ipex-quantization/IntelPytorch_Quantization.ipynb) : This code sample will quantize a ResNet50 model while using Intel® Extension for PyTorch (IPEX). The model will run inference with FP32 and INT8 precision, including static INT8 quantization and dynamic INT8 quantization. During Static Quantization, the model calibrated with the CIFAR10 dataset. The inference time will be compared, showcasing the speedup of INT8 Quantization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
