---
# Source: kserve/templates/clusterservingruntimes.yaml
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-lgbserver
spec:
  annotations:
    prometheus.kserve.io/port: '8080'
    prometheus.kserve.io/path: "/metrics"
  supportedModelFormats:
    - name: lightgbm
      version: "2"
      autoSelect: true
  protocolVersions:
    - v1
  containers:
    - name: kserve-container
      image: "kserve/lgbserver:v0.11.0"
      args:
        - --model_name={{.Name}}
        - --model_dir=/mnt/models
        - --http_port=8080
        - --nthread=1
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
---
# Source: kserve/templates/clusterservingruntimes.yaml
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-mlserver
spec:
  annotations:
    # mlserver version 1.1.0 uses port 8082 as default instead of 8080.
    prometheus.kserve.io/port: '8080'
    prometheus.kserve.io/path: "/metrics"
  supportedModelFormats:
    - name: sklearn
      version: "0"
      autoSelect: true
    - name: xgboost
      version: "1"
      autoSelect: true
    - name: lightgbm
      version: "3"
      autoSelect: true
    - name: mlflow
      version: "1"
      autoSelect: true
  protocolVersions:
    - v2
  containers:
    - name: kserve-container
      image: "docker.io/seldonio/mlserver:1.3.2"
      env:
        - name: "MLSERVER_MODEL_IMPLEMENTATION"
          value: "{{.Labels.modelClass}}"
        - name: "MLSERVER_HTTP_PORT"
          value: "8080"
        - name: "MLSERVER_GRPC_PORT"
          value: "9000"
        - name: "MODELS_DIR"
          value: "/mnt/models"
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
---
# Source: kserve/templates/clusterservingruntimes.yaml
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-paddleserver
spec:
  annotations:
    prometheus.kserve.io/port: '8080'
    prometheus.kserve.io/path: "/metrics"
  supportedModelFormats:
    - name: paddle
      version: "2"
      autoSelect: true
  protocolVersions:
    - v1
  containers:
    - name: kserve-container
      image: "kserve/paddleserver:v0.11.0"
      args:
        - --model_name={{.Name}}
        - --model_dir=/mnt/models
        - --http_port=8080
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
---
# Source: kserve/templates/clusterservingruntimes.yaml
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-pmmlserver
spec:
  annotations:
    prometheus.kserve.io/port: '8080'
    prometheus.kserve.io/path: "/metrics"
  supportedModelFormats:
    - name: pmml
      version: "3"
      autoSelect: true
    - name: pmml
      version: "4"
      autoSelect: true
  protocolVersions:
    - v1
  containers:
    - name: kserve-container
      image: "kserve/pmmlserver:v0.11.0"
      args:
        - --model_name={{.Name}}
        - --model_dir=/mnt/models
        - --http_port=8080
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
---
# Source: kserve/templates/clusterservingruntimes.yaml
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-sklearnserver
spec:
  annotations:
    prometheus.kserve.io/port: '8080'
    prometheus.kserve.io/path: "/metrics"
  supportedModelFormats:
    - name: sklearn
      version: "1"
      autoSelect: true
  protocolVersions:
    - v1
  containers:
    - name: kserve-container
      image: "kserve/sklearnserver:v0.11.0"
      args:
        - --model_name={{.Name}}
        - --model_dir=/mnt/models
        - --http_port=8080
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
---
# Source: kserve/templates/clusterservingruntimes.yaml
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-tensorflow-serving
spec:
  annotations:
    prometheus.kserve.io/port: '8080'
    prometheus.kserve.io/path: "/metrics"
  supportedModelFormats:
    - name: tensorflow
      version: "1"
      autoSelect: true
    - name: tensorflow
      version: "2"
      autoSelect: true
  protocolVersions:
    - v1
    - grpc-v1
  containers:
    - name: kserve-container
      image: "intel/intel-extension-for-tensorflow:serving-cpu"
      command: [/usr/local/bin/tensorflow_model_server]
      env:
        - name: ITEX_OMP_THREADPOOL
          value: '1'
      args:
        - --model_name={{.Name}}
        - --port=9000
        - --rest_api_port=8080
        - --model_base_path=/mnt/models
        - --rest_api_timeout_in_ms=60000
        - --tensorflow_plugins=/itex/itex-bazel-bin/itex
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
---
# Source: kserve/templates/clusterservingruntimes.yaml
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-torchserve
spec:
  annotations:
    prometheus.kserve.io/port: '8082'
    prometheus.kserve.io/path: "/metrics"
  supportedModelFormats:
    - name: pytorch
      version: "1"
      autoSelect: true
  protocolVersions:
    - v1
    - v2
    - grpc-v1
  containers:
    - name: kserve-container
      image: "intel/intel-extension-for-pytorch:2.2.0-serving-cpu-kserve"
      args:
        - torchserve
        - --start
        - --model-store=/mnt/models/model-store
        - --ts-config=/mnt/models/config/config.properties
      env:
        - name: "TS_SERVICE_ENVELOPE"
          value: "{{.Labels.serviceEnvelope}}"
      imagePullPolicy: Always
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
---
# Source: kserve/templates/clusterservingruntimes.yaml
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-tritonserver
spec:
  annotations:
    prometheus.kserve.io/port: '8002'
    prometheus.kserve.io/path: "/metrics"
  supportedModelFormats:
    - name: tensorrt
      version: "8"
      autoSelect: true
    - name: tensorflow
      version: "1"
      autoSelect: true
    - name: tensorflow
      version: "2"
      autoSelect: true
    - name: onnx
      version: "1"
      autoSelect: true
    - name: pytorch
      version: "1"
    - name: triton
      version: "2"
      autoSelect: true
  protocolVersions:
    - v2
    - grpc-v2
  containers:
    - name: kserve-container
      image: "nvcr.io/nvidia/tritonserver:23.05-py3"
      args:
        - tritonserver
        - --model-store=/mnt/models
        - --grpc-port=9000
        - --http-port=8080
        - --allow-grpc=true
        - --allow-http=true
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
---
# Source: kserve/templates/clusterservingruntimes.yaml
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-xgbserver
spec:
  annotations:
    prometheus.kserve.io/port: '8080'
    prometheus.kserve.io/path: "/metrics"
  supportedModelFormats:
    - name: xgboost
      version: "1"
      autoSelect: true
  protocolVersions:
    - v1
  containers:
    - name: kserve-container
      image: "kserve/xgbserver:v0.11.0"
      args:
        - --model_name={{.Name}}
        - --model_dir=/mnt/models
        - --http_port=8080
        - --nthread=1
      resources:
        requests:
          cpu: "1"
          memory: 2Gi
        limits:
          cpu: "1"
          memory: 2Gi
